{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f485cc03-88e6-44d7-b754-79247d561f56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Libraries management\n",
    "from pyspark import pipelines as pl\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    " \n",
    "volume_path = \"/Volumes/workspace/damg7370/datastore/schemadrift_addnewcolumns/customer_*.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b3204c7-ebb3-4893-b4b9-3144afcb3943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pl.create_streaming_table(\"demo_cust_bronze_addcols\")\n",
    " \n",
    "@pl.append_flow(\n",
    "\n",
    "    target=\"demo_cust_bronze_addcols\",\n",
    "\n",
    "    name=\"demo_cust_bronze_addcols_ingest_flow\"\n",
    "\n",
    ")\n",
    "\n",
    "def demo_cust_bronze_addcols_ingest_flow():\n",
    "\n",
    "    df = (\n",
    "\n",
    "        spark.readStream\n",
    "\n",
    "            .format(\"cloudFiles\")\n",
    "\n",
    "            .option(\"cloudFiles.format\", \"json\")\n",
    "\n",
    "            .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "\n",
    "            .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\")   # <-- IMPORTANT\n",
    "\n",
    "            .load(volume_path)\n",
    "\n",
    "    )\n",
    "\n",
    "    return (\n",
    "\n",
    "        df.withColumn(\"ingestion_datetime\", current_timestamp())\n",
    "\n",
    "          .withColumn(\"source_filename\", col(\"_metadata.file_path\"))\n",
    "\n",
    "    )\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "575c383d-8af0-4439-9f11-f351a118ce4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# For structural consistency only â€” NOT USED in addNewColumns\n",
    "def process__rescue_data_new_fields(df):\n",
    "    return df\n",
    " \n",
    "def process__rescue_data_datatype_change(df, target_schema):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d91d794-cdbe-4160-b4e4-2c310ab95c3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "updated_datatypes = StructType([\n",
    "    StructField(\"signupDate\", DateType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac772917-575f-4509-a764-a9c6b412200f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pl.create_streaming_table(\n",
    "    name=\"demo_cust_silver_addcols\",\n",
    "    expect_all_or_drop={\"valid_id\": \"CustomerID IS NOT NULL\"}\n",
    ")\n",
    "@pl.append_flow(\n",
    "    target=\"demo_cust_silver_addcols\",\n",
    "    name=\"demo_cust_silver_addcols_clean_flow\"\n",
    ")\n",
    "def demo_cust_silver_addcols_clean_flow():\n",
    "    df = spark.readStream.table(\"demo_cust_bronze_addcols\")\n",
    " \n",
    "    # Calls below do nothing but keep structure consistent\n",
    "    df = process__rescue_data_new_fields(df)\n",
    "    df = process__rescue_data_datatype_change(df, updated_datatypes)\n",
    " \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Demo_SchemaDrift_AddNewColumns",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
